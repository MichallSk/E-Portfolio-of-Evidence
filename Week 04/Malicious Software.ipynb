{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a446f667",
   "metadata": {},
   "source": [
    "# Section 1: File Interity checker\n",
    "This notebook scans the `files_to_hash` folder, computes SHA-256 digests, and records the results with timestamps in `hash_results.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "add0a03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import csv\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "SOURCE_DIR = Path.cwd() / \"files_to_hash\"\n",
    "OUTPUT_CSV = Path.cwd() / \"hash_results.csv\"\n",
    "\n",
    "def sha256_file(path: Path) -> str:\n",
    "    \"\"\"Return the SHA-256 hex digest of the file at `path`.\"\"\"\n",
    "    hasher = hashlib.sha256()\n",
    "    with path.open(\"rb\") as handle:\n",
    "        for chunk in iter(lambda: handle.read(8192), b\"\"):\n",
    "            hasher.update(chunk)\n",
    "    return hasher.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fef4e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3 files. Results saved to c:\\Users\\Micha\\OneDrive\\My Time at Goldsmiths\\Year 3\\Networks and System Security\\E-Portfolio of Evidence\\Week 04\\hash_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Micha\\AppData\\Local\\Temp\\ipykernel_22284\\315605800.py:5: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  timestamp = datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'filename': 'checklist.md',\n",
       "  'sha256': '854a628d5c411b0000838771adbff3a7657ddf50a7ac22c6b18e6ed535cd413c',\n",
       "  'timestamp': '2025-12-10T12:58:22Z'},\n",
       " {'filename': 'network_notes.txt',\n",
       "  'sha256': '801ee3a1b47e77ddf9d0db5ebd932ab6fac783b69feadf20b0a31085a8331519',\n",
       "  'timestamp': '2025-12-10T12:58:22Z'},\n",
       " {'filename': 'password_policies.txt',\n",
       "  'sha256': 'bd8970a3858ab0d1659505cf4ec59fabae1db068f0c06b58d701fde8c09aa687',\n",
       "  'timestamp': '2025-12-10T12:58:22Z'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not SOURCE_DIR.exists():\n",
    "    raise FileNotFoundError(f\"Expected directory missing: {SOURCE_DIR}\")\n",
    "\n",
    "files = sorted([p for p in SOURCE_DIR.iterdir() if p.is_file()], key=lambda p: p.name.lower())\n",
    "timestamp = datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\"\n",
    "\n",
    "OUTPUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "records = []\n",
    "for file_path in files:\n",
    "    digest = sha256_file(file_path)\n",
    "    records.append({\n",
    "        \"filename\": file_path.name,\n",
    "        \"sha256\": digest,\n",
    "        \"timestamp\": timestamp,\n",
    "    })\n",
    "\n",
    "with OUTPUT_CSV.open(\"w\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=[\"filename\", \"sha256\", \"timestamp\"])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(records)\n",
    "\n",
    "print(f\"Processed {len(records)} files. Results saved to {OUTPUT_CSV}\")\n",
    "records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3acdc90",
   "metadata": {},
   "source": [
    "## Section 2: Detecting Suspicious File Changes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "facda78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Micha\\AppData\\Local\\Temp\\ipykernel_22284\\627098694.py:7: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  {\"filename\": \"network_notes.txt\", \"sha256\": sha256_file(SOURCE_DIR / \"network_notes.txt\"), \"timestamp\": datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\"},\n",
      "C:\\Users\\Micha\\AppData\\Local\\Temp\\ipykernel_22284\\627098694.py:8: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  {\"filename\": \"password_policies.txt\", \"sha256\": \"DEADBEEF\", \"timestamp\": datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\"},\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'modified': ['password_policies.txt'], 'missing': ['checklist.md'], 'new': []}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_records = {record[\"filename\"]: record for record in records}\n",
    "\n",
    "# Simulate modified and missing files relative to baseline\n",
    "current_snapshot = {\n",
    "    entry[\"filename\"]: entry\n",
    "    for entry in [\n",
    "        {\"filename\": \"network_notes.txt\", \"sha256\": sha256_file(SOURCE_DIR / \"network_notes.txt\"), \"timestamp\": datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\"},\n",
    "        {\"filename\": \"password_policies.txt\", \"sha256\": \"DEADBEEF\", \"timestamp\": datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\"},\n",
    "        # checklist.md missing on purpose to simulate deletion\n",
    "    ]\n",
    "}\n",
    "\n",
    "changes = {\"modified\": [], \"missing\": [], \"new\": []}\n",
    "\n",
    "for filename, baseline_entry in baseline_records.items():\n",
    "    current_entry = current_snapshot.get(filename)\n",
    "    if not current_entry:\n",
    "        changes[\"missing\"].append(filename)\n",
    "        continue\n",
    "    if current_entry[\"sha256\"].lower() != baseline_entry[\"sha256\"].lower():\n",
    "        changes[\"modified\"].append(filename)\n",
    "\n",
    "for filename in current_snapshot.keys() - baseline_records.keys():\n",
    "    changes[\"new\"].append(filename)\n",
    "\n",
    "changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4469a5",
   "metadata": {},
   "source": [
    "## Section 3: Signature-Based Malware Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aab5564c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No suspicious patterns found.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "SIGNATURES = [r\"eval\\(\", r\"base64\\.b64decode\", r\"socket\\.connect\", r\"exec\\(\", r\"import os\"]\n",
    "signature_patterns = [re.compile(sig) for sig in SIGNATURES]\n",
    "\n",
    "def scan_file_for_signatures(path: Path) -> Dict[str, int]:\n",
    "    \"\"\"Return a dict of signature matches counts for the given file.\"\"\"\n",
    "    try:\n",
    "        text = path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    except Exception as exc:\n",
    "        print(f\"Could not read {path}: {exc}\")\n",
    "        return {}\n",
    "\n",
    "    hits: Dict[str, int] = {}\n",
    "    for pattern, signature in zip(signature_patterns, SIGNATURES):\n",
    "        matches = pattern.findall(text)\n",
    "        if matches:\n",
    "            hits[signature] = len(matches)\n",
    "    return hits\n",
    "\n",
    "scan_results = {}\n",
    "for file_path in SOURCE_DIR.iterdir():\n",
    "    if not file_path.is_file():\n",
    "        continue\n",
    "    matches = scan_file_for_signatures(file_path)\n",
    "    if matches:\n",
    "        scan_results[file_path.name] = matches\n",
    "\n",
    "scan_results if scan_results else \"No suspicious patterns found.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7ca3ea",
   "metadata": {},
   "source": [
    "## Section 4: Worm Propagation Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2bd7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "def simulate_worm(total_hosts: int = 100, initially_infected: int = 1, steps: int = 20, scan_attempts_per_step: int = 5) -> Counter:\n",
    "    \"\"\"Simulate worm spread by random scanning across hosts.\"\"\"\n",
    "    infected = set(random.sample(range(total_hosts), initially_infected))\n",
    "    history = Counter({\"infected\": len(infected)})\n",
    "\n",
    "    for step in range(1, steps + 1):\n",
    "        new_infections = set()\n",
    "        for host in infected:\n",
    "            for _ in range(scan_attempts_per_step):\n",
    "                target = random.randrange(total_hosts)\n",
    "                if target not in infected:\n",
    "                    new_infections.add(target)\n",
    "        infected |= new_infections\n",
    "        history[step] = len(infected)\n",
    "        if len(infected) == total_hosts:\n",
    "            break\n",
    "\n",
    "    return history\n",
    "\n",
    "random.seed(42)\n",
    "propagation_history = simulate_worm(total_hosts=200, initially_infected=3, steps=15, scan_attempts_per_step=10)\n",
    "propagation_history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp4ai",
   "language": "python",
   "name": "dp4ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
